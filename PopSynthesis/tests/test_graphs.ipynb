{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.data import Data, Batch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Households Data:\n",
      "   household_id income_level  num_rooms  household_size\n",
      "0             1          low          2               3\n",
      "1             2       medium          3               4\n",
      "2             3         high          5               2\n",
      "\n",
      "Persons Data:\n",
      "   person_id  household_id  age gender    role\n",
      "0          1             1   35      M  Parent\n",
      "1          2             1   33      F  Parent\n",
      "2          3             1    5      M   Child\n",
      "3          4             2   40      M  Parent\n",
      "4          5             2   38      F  Parent\n",
      "5          6             2   15      M   Child\n",
      "6          7             2   10      F   Child\n",
      "7          8             3   50      M  Parent\n",
      "8          9             3   48      F  Parent\n"
     ]
    }
   ],
   "source": [
    "### Create new mock data ###\n",
    "\n",
    "# Household Data\n",
    "households_data = {\n",
    "    \"household_id\": [1, 2, 3],\n",
    "    \"income_level\": [\"low\", \"medium\", \"high\"],\n",
    "    \"num_rooms\": [2, 3, 5],\n",
    "    \"household_size\": [3, 4, 2]\n",
    "}\n",
    "households_df = pd.DataFrame(households_data)\n",
    "\n",
    "# Person Data\n",
    "persons_data = {\n",
    "    \"person_id\": [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "    \"household_id\": [1, 1, 1, 2, 2, 2, 2, 3, 3],  # Mapping to households\n",
    "    \"age\": [35, 33, 5, 40, 38, 15, 10, 50, 48],\n",
    "    \"gender\": [\"M\", \"F\", \"M\", \"M\", \"F\", \"M\", \"F\", \"M\", \"F\"],\n",
    "    \"role\": [\"Parent\", \"Parent\", \"Child\", \"Parent\", \"Parent\", \"Child\", \"Child\", \"Parent\", \"Parent\"]\n",
    "}\n",
    "persons_df = pd.DataFrame(persons_data)\n",
    "\n",
    "print(\"Households Data:\")\n",
    "print(households_df)\n",
    "\n",
    "print(\"\\nPersons Data:\")\n",
    "print(persons_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transformed Households Data:\n",
      "   household_id  num_rooms  household_size  income_level_high  \\\n",
      "0             1   0.000000               3                0.0   \n",
      "1             2   0.333333               4                0.0   \n",
      "2             3   1.000000               2                1.0   \n",
      "\n",
      "   income_level_low  income_level_medium  \n",
      "0               1.0                  0.0  \n",
      "1               0.0                  1.0  \n",
      "2               0.0                  0.0  \n",
      "\n",
      "Transformed Persons Data:\n",
      "   person_id  household_id       age  gender_F  gender_M    role\n",
      "0          1             1  0.293366       0.0       1.0  Parent\n",
      "1          2             1  0.164571       1.0       0.0  Parent\n",
      "2          3             1 -1.638559       0.0       1.0   Child\n",
      "3          4             2  0.615354       0.0       1.0  Parent\n",
      "4          5             2  0.486559       1.0       0.0  Parent\n",
      "5          6             2 -0.994584       0.0       1.0   Child\n",
      "6          7             2 -1.316572       1.0       0.0   Child\n",
      "7          8             3  1.259329       0.0       1.0  Parent\n",
      "8          9             3  1.130534       1.0       0.0  Parent\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ==== 1. Initialize Encoders ====\n",
    "age_scaler = StandardScaler()\n",
    "room_scaler = MinMaxScaler()\n",
    "income_encoder = OneHotEncoder(sparse_output=False)\n",
    "gender_encoder = OneHotEncoder(sparse_output=False)\n",
    "# role_encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# ==== 2. Transform Household Data ====\n",
    "households_df[\"num_rooms\"] = room_scaler.fit_transform(households_df[[\"num_rooms\"]])\n",
    "income_encoded = income_encoder.fit_transform(households_df[[\"income_level\"]])\n",
    "\n",
    "# Convert encoded income to DataFrame\n",
    "income_columns = income_encoder.get_feature_names_out([\"income_level\"])\n",
    "households_encoded_df = households_df.drop(columns=[\"income_level\"])\n",
    "households_encoded_df[income_columns] = income_encoded\n",
    "\n",
    "# ==== 3. Transform Person Data ====\n",
    "persons_df[\"age\"] = age_scaler.fit_transform(persons_df[[\"age\"]])\n",
    "gender_encoded = gender_encoder.fit_transform(persons_df[[\"gender\"]])\n",
    "# role_encoded = role_encoder.fit_transform(persons_df[[\"role\"]])\n",
    "\n",
    "# Convert encoded gender & role to DataFrame\n",
    "gender_columns = gender_encoder.get_feature_names_out([\"gender\"])\n",
    "# role_columns = role_encoder.get_feature_names_out([\"role\"])\n",
    "persons_encoded_df = persons_df.drop(columns=[\"gender\", \"role\"])\n",
    "persons_encoded_df[gender_columns] = gender_encoded\n",
    "# persons_encoded_df[role_columns] = role_encoded\n",
    "persons_encoded_df[\"role\"] = persons_df[\"role\"]\n",
    "\n",
    "# ==== 4. Display Encoded Data ====\n",
    "print(\"\\nTransformed Households Data:\")\n",
    "print(households_encoded_df)\n",
    "\n",
    "print(\"\\nTransformed Persons Data:\")\n",
    "print(persons_encoded_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[9, 7], edge_index=[2, 20], edge_attr=[20, 3], batch=[9], ptr=[4])\n"
     ]
    }
   ],
   "source": [
    "# ==== 2. Create Graphs for Each Household ====\n",
    "household_graphs = []\n",
    "relationship_types = [\"parent-child\", \"spouse\", \"sibling\"]\n",
    "relationship_encoder = OneHotEncoder(sparse_output=False)\n",
    "relationship_encoded = relationship_encoder.fit_transform([[rel] for rel in relationship_types])\n",
    "relationship_mapping = {rel: torch.tensor(relationship_encoded[i], dtype=torch.float) for i, rel in enumerate(relationship_types)}\n",
    "\n",
    "for household_id in households_encoded_df[\"household_id\"].unique():\n",
    "    # Get household attributes\n",
    "    household_attr = households_encoded_df[households_encoded_df[\"household_id\"] == household_id].drop(columns=[\"household_id\", \"household_size\"]).values\n",
    "    household_attr = torch.tensor(household_attr, dtype=torch.float)\n",
    "\n",
    "    # Get people in the household\n",
    "    household_people = persons_encoded_df[persons_encoded_df[\"household_id\"] == household_id]\n",
    "    node_features = torch.tensor(household_people.drop(columns=[\"household_id\", \"person_id\", \"role\"]).values, dtype=torch.float)\n",
    "\n",
    "    # Assign unique node indices\n",
    "    person_ids = household_people[\"person_id\"].tolist()\n",
    "    person_index_map = {pid: i for i, pid in enumerate(person_ids)}\n",
    "\n",
    "    mapping_id_role = dict(zip(household_people[\"person_id\"], household_people[\"role\"]))\n",
    "    mapping_indx_role = {person_index_map[key]: val for key, val in mapping_id_role.items()}\n",
    "\n",
    "    # Define edges based on relationships (Mock Example)\n",
    "    edge_index_list = []\n",
    "    edge_attr_list = []\n",
    "    for i in range(len(person_ids)):  # Simple pairwise connection (replace with real relationships)\n",
    "        for j in range(len(person_ids)):\n",
    "          if i != j:\n",
    "            edge_index_list.append([person_index_map[person_ids[i]], person_index_map[person_ids[j]]])\n",
    "            if mapping_indx_role[i] == \"Parent\" and mapping_indx_role[j] == \"Child\":\n",
    "              edge_attr_list.append(relationship_mapping[\"parent-child\"])\n",
    "            elif mapping_indx_role[i] == \"Child\" and mapping_indx_role[j] == \"Parent\":\n",
    "              edge_attr_list.append(relationship_mapping[\"parent-child\"])\n",
    "            elif mapping_indx_role[i] == \"Parent\" and mapping_indx_role[j] == \"Parent\":\n",
    "              edge_attr_list.append(relationship_mapping[\"spouse\"])\n",
    "            elif mapping_indx_role[i] == \"Child\" and mapping_indx_role[j] == \"Child\":\n",
    "              edge_attr_list.append(relationship_mapping[\"sibling\"])\n",
    "            else:\n",
    "              raise ValueError(\"something is wrong\")\n",
    "\n",
    "    # Convert edge lists to tensors\n",
    "    edge_index = torch.tensor(edge_index_list, dtype=torch.long).T if edge_index_list else torch.empty((2, 0), dtype=torch.long)\n",
    "    edge_attr = torch.stack(edge_attr_list) if edge_attr_list else torch.empty((0, len(relationship_types)), dtype=torch.float)\n",
    "\n",
    "    # Broadcast global attributes to all nodes\n",
    "    global_attr = household_attr.repeat(node_features.size(0), 1)\n",
    "\n",
    "    # Create PyG Data object\n",
    "    graph_data = Data(x=torch.cat([node_features, global_attr], dim=1), edge_index=edge_index, edge_attr=edge_attr)\n",
    "    household_graphs.append(graph_data)\n",
    "\n",
    "# ==== 3. Batch All Graphs Together ====\n",
    "batched_graph = Batch.from_data_list(household_graphs)\n",
    "\n",
    "# ==== 4. Print Graph Information ====\n",
    "print(batched_graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2934,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000],\n",
       "        [ 0.1646,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000],\n",
       "        [-1.6386,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000],\n",
       "        [ 0.6154,  0.0000,  1.0000,  0.3333,  0.0000,  0.0000,  1.0000],\n",
       "        [ 0.4866,  1.0000,  0.0000,  0.3333,  0.0000,  0.0000,  1.0000],\n",
       "        [-0.9946,  0.0000,  1.0000,  0.3333,  0.0000,  0.0000,  1.0000],\n",
       "        [-1.3166,  1.0000,  0.0000,  0.3333,  0.0000,  0.0000,  1.0000],\n",
       "        [ 1.2593,  0.0000,  1.0000,  1.0000,  1.0000,  0.0000,  0.0000],\n",
       "        [ 1.1305,  1.0000,  0.0000,  1.0000,  1.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_graph.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 3\n"
     ]
    }
   ],
   "source": [
    "household_attr_dim = 4  # Number of household attributes (last 4 columns)\n",
    "node_attr_dim = batched_graph.x.shape[1] - household_attr_dim  # Remaining columns are node attributes\n",
    "print(household_attr_dim, node_attr_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.2934,  0.0000,  1.0000],\n",
       "         [ 0.1646,  1.0000,  0.0000],\n",
       "         [-1.6386,  0.0000,  1.0000],\n",
       "         [ 0.6154,  0.0000,  1.0000],\n",
       "         [ 0.4866,  1.0000,  0.0000],\n",
       "         [-0.9946,  0.0000,  1.0000],\n",
       "         [-1.3166,  1.0000,  0.0000],\n",
       "         [ 1.2593,  0.0000,  1.0000],\n",
       "         [ 1.1305,  1.0000,  0.0000]]),\n",
       " tensor([[0.0000, 0.0000, 1.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 1.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 1.0000, 0.0000],\n",
       "         [0.3333, 0.0000, 0.0000, 1.0000],\n",
       "         [0.3333, 0.0000, 0.0000, 1.0000],\n",
       "         [0.3333, 0.0000, 0.0000, 1.0000],\n",
       "         [0.3333, 0.0000, 0.0000, 1.0000],\n",
       "         [1.0000, 1.0000, 0.0000, 0.0000],\n",
       "         [1.0000, 1.0000, 0.0000, 0.0000]]))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_pp_att_hh_att(batched_graph, household_attr_dim, node_attr_dim):\n",
    "    # Extract node attributes (excluding household attributes)\n",
    "    node_attr = batched_graph.x[:, :node_attr_dim]  # [num_nodes, node_attr_dim]\n",
    "    # node_attr = torch.cat((node_attr.T, torch.zeros(1,node_attr.shape[0]))).T\n",
    "\n",
    "    # Extract household attributes\n",
    "    household_attr = batched_graph.x[:, -household_attr_dim:]  # [num_nodes, household_attr_dim]\n",
    "    return node_attr, household_attr\n",
    "split_pp_att_hh_att(batched_graph, household_attr_dim, node_attr_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.data import Data, Batch\n",
    "import random\n",
    "\n",
    "# ==== 1. DEFINE UPDATED GAT MODEL ====\n",
    "class GATHouseholdModel(nn.Module):\n",
    "    def __init__(self, given_dim, target_dim, hidden_dim, num_heads, edge_dim):\n",
    "        super().__init__()\n",
    "        self.gat1 = GATConv(target_dim, hidden_dim, heads=num_heads, concat=True)\n",
    "        self.gat2 = GATConv(hidden_dim * num_heads, given_dim, heads=1, concat=False)\n",
    "        \n",
    "        # Edge attribute predictor (only takes node embeddings)\n",
    "        self.edge_mlp = nn.Sequential(\n",
    "            nn.Linear(2 * given_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, edge_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.gat1(x, edge_index).relu()\n",
    "        x = self.gat2(x, edge_index)\n",
    "        \n",
    "        # Edge prediction using node embeddings\n",
    "        row, col = edge_index\n",
    "        edge_input = torch.cat([x[row], x[col]], dim=1)\n",
    "        edge_pred = self.edge_mlp(edge_input)\n",
    "        \n",
    "        return x, edge_pred\n",
    "\n",
    "# ==== 2. SPLIT DATA INTO TRAINING & CRITIC ====\n",
    "def split_data(graphs, critic_ratio=0.2):\n",
    "    random.shuffle(graphs)\n",
    "    split_idx = int(len(graphs) * (1 - critic_ratio))\n",
    "    train_graphs = graphs[:split_idx]\n",
    "    critic_graphs = graphs[split_idx:]\n",
    "    return train_graphs, critic_graphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train Loss = 1.2130, Critic Loss = 1.2338\n",
      "Epoch 50: Train Loss = 0.8326, Critic Loss = 1.0260\n",
      "Epoch 100: Train Loss = 0.5679, Critic Loss = 0.8624\n",
      "Epoch 150: Train Loss = 0.4969, Critic Loss = 0.8045\n",
      "Epoch 200: Train Loss = 0.4795, Critic Loss = 0.8078\n",
      "Epoch 250: Train Loss = 0.4758, Critic Loss = 0.8155\n",
      "Epoch 300: Train Loss = 0.4752, Critic Loss = 0.8189\n",
      "Epoch 350: Train Loss = 0.4751, Critic Loss = 0.8196\n",
      "Epoch 400: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 450: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 500: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 550: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 600: Train Loss = 0.4751, Critic Loss = 0.8200\n",
      "Epoch 650: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 700: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 750: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 800: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 850: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 900: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 950: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 1000: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 1050: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 1100: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 1150: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 1200: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 1250: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 1300: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 1350: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 1400: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 1450: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 1500: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 1550: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 1600: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 1650: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 1700: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 1750: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 1800: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 1850: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 1900: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 1950: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 2000: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 2050: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 2100: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 2150: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 2200: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 2250: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 2300: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 2350: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 2400: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 2450: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 2500: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 2550: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 2600: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 2650: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 2700: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 2750: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 2800: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 2850: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 2900: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 2950: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 3000: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 3050: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 3100: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 3150: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 3200: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 3250: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 3300: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 3350: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 3400: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 3450: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 3500: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 3550: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 3600: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 3650: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 3700: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 3750: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 3800: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 3850: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 3900: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 3950: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 4000: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 4050: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 4100: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 4150: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 4200: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 4250: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 4300: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 4350: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 4400: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 4450: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 4500: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 4550: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 4600: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 4650: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 4700: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 4750: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 4800: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 4850: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 4900: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 4950: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 5000: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 5050: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 5100: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 5150: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 5200: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 5250: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 5300: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 5350: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 5400: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 5450: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 5500: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 5550: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 5600: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 5650: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 5700: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 5750: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 5800: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 5850: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 5900: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 5950: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 6000: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 6050: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 6100: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 6150: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 6200: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 6250: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 6300: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 6350: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 6400: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 6450: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 6500: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 6550: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 6600: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 6650: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 6700: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 6750: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 6800: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 6850: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 6900: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 6950: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 7000: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 7050: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 7100: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 7150: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 7200: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 7250: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 7300: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 7350: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 7400: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 7450: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 7500: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 7550: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 7600: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 7650: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 7700: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 7750: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 7800: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 7850: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 7900: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 7950: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 8000: Train Loss = 0.4751, Critic Loss = 0.8199\n",
      "Epoch 8050: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 8100: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 8150: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 8200: Train Loss = 0.4751, Critic Loss = 0.8199\n",
      "Epoch 8250: Train Loss = 0.4751, Critic Loss = 0.8199\n",
      "Epoch 8300: Train Loss = 0.4751, Critic Loss = 0.8199\n",
      "Epoch 8350: Train Loss = 0.4751, Critic Loss = 0.8196\n",
      "Epoch 8400: Train Loss = 0.4751, Critic Loss = 0.8199\n",
      "Epoch 8450: Train Loss = 0.4751, Critic Loss = 0.8199\n",
      "Epoch 8500: Train Loss = 0.4751, Critic Loss = 0.8199\n",
      "Epoch 8550: Train Loss = 0.4751, Critic Loss = 0.8199\n",
      "Epoch 8600: Train Loss = 0.4751, Critic Loss = 0.8200\n",
      "Epoch 8650: Train Loss = 0.4751, Critic Loss = 0.8199\n",
      "Epoch 8700: Train Loss = 0.4751, Critic Loss = 0.8199\n",
      "Epoch 8750: Train Loss = 0.4751, Critic Loss = 0.8199\n",
      "Epoch 8800: Train Loss = 0.4751, Critic Loss = 0.8199\n",
      "Epoch 8850: Train Loss = 0.4751, Critic Loss = 0.8196\n",
      "Epoch 8900: Train Loss = 0.4751, Critic Loss = 0.8199\n",
      "Epoch 8950: Train Loss = 0.4751, Critic Loss = 0.8199\n",
      "Epoch 9000: Train Loss = 0.4751, Critic Loss = 0.8199\n",
      "Epoch 9050: Train Loss = 0.4751, Critic Loss = 0.8200\n",
      "Epoch 9100: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 9150: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 9200: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 9250: Train Loss = 0.4751, Critic Loss = 0.8204\n",
      "Epoch 9300: Train Loss = 0.4751, Critic Loss = 0.8199\n",
      "Epoch 9350: Train Loss = 0.4751, Critic Loss = 0.8199\n",
      "Epoch 9400: Train Loss = 0.4751, Critic Loss = 0.8199\n",
      "Epoch 9450: Train Loss = 0.4751, Critic Loss = 0.8199\n",
      "Epoch 9500: Train Loss = 0.4751, Critic Loss = 0.8200\n",
      "Epoch 9550: Train Loss = 0.4751, Critic Loss = 0.8200\n",
      "Epoch 9600: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 9650: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 9700: Train Loss = 0.4751, Critic Loss = 0.8199\n",
      "Epoch 9750: Train Loss = 0.4751, Critic Loss = 0.8201\n",
      "Epoch 9800: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 9850: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 9900: Train Loss = 0.4751, Critic Loss = 0.8198\n",
      "Epoch 9950: Train Loss = 0.4751, Critic Loss = 0.8193\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example: Assume we have a list of household graphs\n",
    "train_graphs, critic_graphs = split_data(batched_graph.to_data_list())\n",
    "\n",
    "# ==== 3. TRAINING LOOP ====\n",
    "model = GATHouseholdModel(given_dim=3, hidden_dim=8, target_dim=4, num_heads=4, edge_dim=3).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "batched_train = Batch.from_data_list(train_graphs).to(device)\n",
    "batched_critic = Batch.from_data_list(critic_graphs).to(device)\n",
    "\n",
    "train_pp_atts, train_hh_atts  = split_pp_att_hh_att(batched_train, household_attr_dim, node_attr_dim)\n",
    "critic_pp_atts, critic_hh_atts = split_pp_att_hh_att(batched_critic, household_attr_dim, node_attr_dim)\n",
    "\n",
    "for epoch in range(10000):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    node_pred, edge_pred = model(train_hh_atts, batched_train.edge_index)\n",
    "    loss = loss_fn(node_pred, train_pp_atts) + loss_fn(edge_pred, batched_train.edge_attr)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 50 == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            node_pred_critic, edge_pred_critic = model(critic_hh_atts, batched_critic.edge_index)\n",
    "            critic_loss = loss_fn(node_pred_critic, critic_pp_atts) + loss_fn(edge_pred_critic, batched_critic.edge_attr)\n",
    "        print(f\"Epoch {epoch}: Train Loss = {loss.item():.4f}, Critic Loss = {critic_loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[3, 4], edge_index=[2, 6])\n"
     ]
    }
   ],
   "source": [
    "first_graph = batched_graph.to_data_list()[0]  # Get the first graph\n",
    "\n",
    "# Extract number of nodes in the first graph\n",
    "num_nodes_first_graph = first_graph.x.shape[0]\n",
    "\n",
    "# Extract only household attributes and broadcast them to all nodes\n",
    "household_attr = first_graph.x[0, -4:].unsqueeze(0).repeat(num_nodes_first_graph, 1)\n",
    "\n",
    "# Create a new graph with only the structure and household attributes\n",
    "graph_for_test = Data(\n",
    "    x=household_attr,  # Use only household attributes, replicated for all nodes\n",
    "    edge_index=first_graph.edge_index  # Keep edges\n",
    ")\n",
    "\n",
    "print(graph_for_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node Predictions:\n",
      " tensor([[0.2573, 0.4494, 0.2307],\n",
      "        [0.2573, 0.4494, 0.2307],\n",
      "        [0.2573, 0.4494, 0.2307]])\n",
      "Edge Predictions:\n",
      " tensor([[0.2737, 0.0573, 0.4204],\n",
      "        [0.2737, 0.0573, 0.4204],\n",
      "        [0.2737, 0.0573, 0.4204],\n",
      "        [0.2737, 0.0573, 0.4204],\n",
      "        [0.2737, 0.0573, 0.4204],\n",
      "        [0.2737, 0.0573, 0.4204]])\n"
     ]
    }
   ],
   "source": [
    "# ==== 4. INFERENCE ====\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    node_pred, edge_pred = model(graph_for_test.x, graph_for_test.edge_index)\n",
    "print(\"Node Predictions:\\n\", node_pred)\n",
    "print(\"Edge Predictions:\\n\", edge_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "popsyn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
